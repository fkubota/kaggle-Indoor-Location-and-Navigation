{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sudden-wallet",
   "metadata": {},
   "source": [
    "# Overview\n",
    "- bssidはwifiの名前を表すものである。\n",
    "- 仮説\n",
    "    - 1Fのwifiは2階に届かないはず。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "photographic-malta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f613900\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "cmd = \"git rev-parse --short HEAD\"\n",
    "hash = subprocess.check_output(cmd.split()).strip().decode('utf-8')\n",
    "print(hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-bullet",
   "metadata": {},
   "source": [
    "# Const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "opposed-innocent",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = '004'\n",
    "DIR_TRAIN = './../data_ignore/input/train/'\n",
    "DIR_TEST = './../data_ignore/input/test/'\n",
    "DIR_WIFI = './../data_ignore/input/wifi/'\n",
    "PATH_SUB = './../data_ignore/input/sample_submission.csv'\n",
    "PATH_99_SUB = './../data/input/floor_99per_acc_sub.csv'\n",
    "DIR_SAVE_IGNORE = f'./../data_ignore/nb/{NB}/'\n",
    "DIR_SAVE = f'./../data/nb/{NB}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "multiple-scope",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_str = '''\n",
    "globals:\n",
    "    seed: 5713\n",
    "    device: cuda\n",
    "    n_label: 24\n",
    "    n_splits: 5\n",
    "    random_sate: 42\n",
    "    lr: 0.001\n",
    "    patience: 10\n",
    "    epoch: 100\n",
    "    batch_size: 512\n",
    "    skip_evaluate_num: 5\n",
    "    num_feats: 20\n",
    "    t_mux: 10\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-stick",
   "metadata": {},
   "source": [
    "# Import everything I need:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "technical-playing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import yaml\n",
    "import types\n",
    "import random\n",
    "import pickle\n",
    "import builtins\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from icecream import ic\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "# from tqdm import tqdm\n",
    "from fastprogress import progress_bar, master_bar\n",
    "from glob import glob\n",
    "from loguru import logger\n",
    "from collections import OrderedDict\n",
    "\n",
    "# sklearn\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-whale",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "completed-tactics",
   "metadata": {
    "executionInfo": {
     "elapsed": 4655,
     "status": "ok",
     "timestamp": 1616479151188,
     "user": {
      "displayName": "ユウキハヤカワ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfXu9o7zmAYL24s4P8H7I0lvSgQUaSfrXi7qemvQ=s64",
      "userId": "00286900621093795459"
     },
     "user_tz": -540
    },
    "id": "7SxgGjwA5Rty"
   },
   "outputs": [],
   "source": [
    "def imports():\n",
    "    for name, val in globals().items():\n",
    "        # module imports\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            yield name, val\n",
    "\n",
    "            # functions / callables\n",
    "        if hasattr(val, '__call__'):\n",
    "            yield name, val\n",
    "\n",
    "\n",
    "def noglobal(f):\n",
    "    '''\n",
    "    ref: https://gist.github.com/raven38/4e4c3c7a179283c441f575d6e375510c\n",
    "    '''\n",
    "    return types.FunctionType(f.__code__,\n",
    "                              dict(imports()),\n",
    "                              f.__name__,\n",
    "                              f.__defaults__,\n",
    "                              f.__closure__\n",
    "                              )\n",
    "\n",
    "\n",
    "def comp_metric(xhat, yhat, fhat, x, y, f):\n",
    "    intermediate = np.sqrt(np.power(xhat-x, 2) + np.power(yhat-y, 2)) + 15 * np.abs(fhat-f)\n",
    "    return intermediate.sum()/xhat.shape[0]\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "studied-couple",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ReadData:\n",
    "    acce: np.ndarray\n",
    "    acce_uncali: np.ndarray\n",
    "    gyro: np.ndarray\n",
    "    gyro_uncali: np.ndarray\n",
    "    magn: np.ndarray\n",
    "    magn_uncali: np.ndarray\n",
    "    ahrs: np.ndarray\n",
    "    wifi: np.ndarray\n",
    "    ibeacon: np.ndarray\n",
    "    waypoint: np.ndarray\n",
    "\n",
    "\n",
    "def read_data_file(data_filename):\n",
    "    acce = []\n",
    "    acce_uncali = []\n",
    "    gyro = []\n",
    "    gyro_uncali = []\n",
    "    magn = []\n",
    "    magn_uncali = []\n",
    "    ahrs = []\n",
    "    wifi = []\n",
    "    ibeacon = []\n",
    "    waypoint = []\n",
    "\n",
    "    with open(data_filename, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    for line_data in lines:\n",
    "        line_data = line_data.strip()\n",
    "        if not line_data or line_data[0] == '#':\n",
    "            continue\n",
    "\n",
    "        line_data = line_data.split('\\t')\n",
    "\n",
    "        if line_data[1] == 'TYPE_ACCELEROMETER':\n",
    "            acce.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n",
    "            continue\n",
    "\n",
    "        if line_data[1] == 'TYPE_ACCELEROMETER_UNCALIBRATED':\n",
    "            acce_uncali.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n",
    "            continue\n",
    "\n",
    "        if line_data[1] == 'TYPE_GYROSCOPE':\n",
    "            gyro.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n",
    "            continue\n",
    "\n",
    "        if line_data[1] == 'TYPE_GYROSCOPE_UNCALIBRATED':\n",
    "            gyro_uncali.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n",
    "            continue\n",
    "\n",
    "        if line_data[1] == 'TYPE_MAGNETIC_FIELD':\n",
    "            magn.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n",
    "            continue\n",
    "\n",
    "        if line_data[1] == 'TYPE_MAGNETIC_FIELD_UNCALIBRATED':\n",
    "            magn_uncali.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n",
    "            continue\n",
    "\n",
    "        if line_data[1] == 'TYPE_ROTATION_VECTOR':\n",
    "            ahrs.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n",
    "            continue\n",
    "\n",
    "        if line_data[1] == 'TYPE_WIFI':\n",
    "            sys_ts = line_data[0]\n",
    "            ssid = line_data[2]\n",
    "            bssid = line_data[3]\n",
    "            rssi = line_data[4]\n",
    "            lastseen_ts = line_data[6]\n",
    "            wifi_data = [sys_ts, ssid, bssid, rssi, lastseen_ts]\n",
    "            wifi.append(wifi_data)\n",
    "            continue\n",
    "\n",
    "        if line_data[1] == 'TYPE_BEACON':\n",
    "            ts = line_data[0]\n",
    "            uuid = line_data[2]\n",
    "            major = line_data[3]\n",
    "            minor = line_data[4]\n",
    "            rssi = line_data[6]\n",
    "            ibeacon_data = [ts, '_'.join([uuid, major, minor]), rssi]\n",
    "            ibeacon.append(ibeacon_data)\n",
    "            continue\n",
    "\n",
    "        if line_data[1] == 'TYPE_WAYPOINT':\n",
    "            waypoint.append([int(line_data[0]), float(line_data[2]), float(line_data[3])])\n",
    "\n",
    "    acce = np.array(acce)\n",
    "    acce_uncali = np.array(acce_uncali)\n",
    "    gyro = np.array(gyro)\n",
    "    gyro_uncali = np.array(gyro_uncali)\n",
    "    magn = np.array(magn)\n",
    "    magn_uncali = np.array(magn_uncali)\n",
    "    ahrs = np.array(ahrs)\n",
    "    wifi = np.array(wifi)\n",
    "    ibeacon = np.array(ibeacon)\n",
    "    waypoint = np.array(waypoint)\n",
    "\n",
    "    return ReadData(acce, acce_uncali, gyro, gyro_uncali, magn, magn_uncali, ahrs, wifi, ibeacon, waypoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-legislation",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-folks",
   "metadata": {},
   "source": [
    "load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "treated-japan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'globals': {'seed': 5713,\n",
       "  'device': 'cuda',\n",
       "  'n_label': 24,\n",
       "  'n_splits': 5,\n",
       "  'random_sate': 42,\n",
       "  'lr': 0.001,\n",
       "  'patience': 10,\n",
       "  'epoch': 100,\n",
       "  'batch_size': 512,\n",
       "  'skip_evaluate_num': 5,\n",
       "  'num_feats': 20,\n",
       "  't_mux': 10}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = yaml.safe_load(config_str)\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-cruise",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sitting-pencil",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(config['globals']['seed'])\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "if not os.path.exists(DIR_SAVE_IGNORE):\n",
    "    os.makedirs(DIR_SAVE_IGNORE)\n",
    "if not os.path.exists(DIR_SAVE):\n",
    "    os.makedirs(DIR_SAVE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-registrar",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "infrared-player",
   "metadata": {
    "executionInfo": {
     "elapsed": 12440,
     "status": "ok",
     "timestamp": 1616479159010,
     "user": {
      "displayName": "ユウキハヤカワ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfXu9o7zmAYL24s4P8H7I0lvSgQUaSfrXi7qemvQ=s64",
      "userId": "00286900621093795459"
     },
     "user_tz": -540
    },
    "id": "g0ytMb1aSnv0"
   },
   "outputs": [],
   "source": [
    "with open(f'{DIR_WIFI}train_all.pkl', 'rb') as f:\n",
    "    df_train = pickle.load( f)\n",
    "with open(f'{DIR_WIFI}test_all.pkl', 'rb') as f:\n",
    "    df_test = pickle.load( f)\n",
    "\n",
    "sample_submission = pd.read_csv(PATH_SUB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-motorcycle",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "marked-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_list = [val.split('_')[0] for val in sample_submission.site_path_timestamp]\n",
    "site_list = sorted(np.unique(site_list).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "broke-collapse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site0 -- start at Mon Mar 29 14:17:54 2021\n",
      "site1 -- start at Mon Mar 29 14:22:06 2021\n",
      "site2 -- start at Mon Mar 29 14:25:35 2021\n",
      "site3 -- start at Mon Mar 29 14:45:20 2021\n",
      "site4 -- start at Mon Mar 29 14:46:42 2021\n",
      "site5 -- start at Mon Mar 29 14:48:20 2021\n",
      "site6 -- start at Mon Mar 29 14:48:44 2021\n",
      "site7 -- start at Mon Mar 29 14:49:16 2021\n",
      "site8 -- start at Mon Mar 29 14:54:41 2021\n",
      "site9 -- start at Mon Mar 29 14:57:14 2021\n",
      "site10 -- start at Mon Mar 29 15:02:39 2021\n",
      "site11 -- start at Mon Mar 29 15:03:56 2021\n",
      "site12 -- start at Mon Mar 29 15:05:12 2021\n",
      "site13 -- start at Mon Mar 29 15:05:22 2021\n",
      "site14 -- start at Mon Mar 29 15:08:59 2021\n",
      "site15 -- start at Mon Mar 29 15:11:27 2021\n",
      "site16 -- start at Mon Mar 29 15:11:36 2021\n",
      "site17 -- start at Mon Mar 29 15:13:46 2021\n",
      "site18 -- start at Mon Mar 29 15:14:27 2021\n",
      "site19 -- start at Mon Mar 29 15:16:05 2021\n",
      "site20 -- start at Mon Mar 29 15:16:56 2021\n",
      "site21 -- start at Mon Mar 29 15:24:53 2021\n",
      "site22 -- start at Mon Mar 29 15:31:14 2021\n",
      "site23 -- start at Mon Mar 29 15:41:26 2021\n",
      "CPU times: user 1h 20min 21s, sys: 7min 45s, total: 1h 28min 7s\n",
      "Wall time: 1h 28min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cols = ['sys_ts', 'ssid ', 'bssid', 'rssi', 'lastseen_ts']\n",
    "# dict_site = {}\n",
    "mb = master_bar(site_list)\n",
    "for i_site, site in enumerate(mb):\n",
    "    print(f'site{i_site} -- start at {time.ctime()}')\n",
    "    path_route_list = sorted(glob(f'./../data_ignore/input/train/{site}/*/*'))\n",
    "    df_wifi = pd.DataFrame(columns=cols)\n",
    "    for i_route, path_route in enumerate(progress_bar(path_route_list, parent=mb)):\n",
    "        floor = path_route.split('/')[-2]\n",
    "        data = read_data_file(path_route).wifi\n",
    "        if len(data) == 0:\n",
    "            continue\n",
    "        df = pd.DataFrame(data, columns=cols)\n",
    "        df['floor'] = floor\n",
    "        df = df.astype({'rssi': 'float32'})\n",
    "        df_wifi = pd.concat([df_wifi, df], axis=0)\n",
    "    \n",
    "    save_path = f'{DIR_SAVE_IGNORE}nb{NB}_wifi_{site}.csv'\n",
    "    df_wifi.to_csv(save_path, index=False)\n",
    "#     dict_site[site] = df_wifi\n",
    "#     if i_site == 0:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-synthetic",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "raw",
   "id": "lyric-range",
   "metadata": {},
   "source": [
    "path = f'{DIR_SAVE_IGNORE}dict_site_wifi.pkl'\n",
    "# === save data as pickle ===\n",
    "with open(path, mode='wb') as f:\n",
    "    pickle.dump(dict_site, f)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dimensional-potter",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
